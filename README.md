
                                                    



# PROJECT ON VISUALISATION OF WEBSITE CLICKSTREAM DATA

By

**ManshiAgrawal(171500182)**

**Nancy Varshney(171500203)**

**Neha Chaudhary(171500205)**

**Shreshth Bharadwaj(171500328)**

Under the Supervision of

**Mr. Vaibhav Diwan**

 
## Department of Computer Engineering and Applications

## IET, GLA University-Mathura

##

##

##

**ABSTRACT**

Nowadays web is becoming a main channel for reaching customers and prospects; Clickstream data generated by websites has become another important enterprise data source. As simple as it sounds for recording every click a customer made, so that we can use clickstream data for modelling user behaviour, gaining valuable customer insights. Clickstream analysis commonly refers to analysing click data and website optimization. Such analysis is typically done to extract insights into website visitor behavior especially social-media or ecommerce websites. Also nowadays online-learning became a trend in education system. We can see many online learning portals which are providing live training on various technologies. To identify potential customers or to identify recommendations for existing customers. Clickstream analysis can be used to figure out which geographies and time zones is most of traffic coming from, and which devices, Browsers (such as its name, versions), time spent, Operating Systems, are used to access the websites, which common paths users take before they do something in site. Analysis of clickstream data in real time(streaming) has more value than batch mode(stored).

**INTRODUCTION**

**GENERAL INTRODUCTION TO THE TOPIC:**

A clickstream is the recording of the client taps on while perusing site or utilizing other programming applications. As the client clicks anyplace in the website page or applications, the activity is logged inside the web server or on a customer, and also conceivably the router, proxy server or web browser. Analysis of clickstream data is valuable for web movement investigation, statistical surveying, programming testing and for dissecting representative profitability. Starting clickstream or snap way information must be gathered from server log documents. JavaScript advancements is utilized for following treat to produce a progression of snap signs from programs or applications continuously. As it were, data was gathered just from &quot;genuine people&quot; tapping on webpages through browsers.

It was impractical to distinguish the snap ways from programs. A clickstream implies arrangement of solicitations, each page asked for by clients produce a signal. These signs can be utilized for graphically portrayal of clickstream revealing.

The primary purpose of clickstream following is to comprehend client conduct and give website admins understanding into what guests are doing on their website. The information can be utilized for different reason, for marketing. Furthermore, scientist, any website admin, blogger or individual with a site can find out about how to enhance their webpage.

Most customers are ignorant of this practice, and its potential for bargaining their protection. Likewise, few ISPs openly admit to this practice. Analysing the information of clients that visit an organization or association&#39;s site can be imperative with a specific end goal to stay focused. This analysis can be utilized to create two discoveries for the organization, the first being an analysis of a client&#39;s clickstream to comprehend utilization patterns, which thus gives an increased comprehension of client conduct. Clickstream analysis can be utilized to enhance consumer loyalty with the website of company and with the company itself. This can produce a business advantage, used to survey the viability of promoting on a page or site of company. Unapproved gathering of clickstream information is thought to be spyware. In any case, approved clickstream information gathering originates from organizations that utilization pick in boards to produce statistical surveying utilizing specialists who are consent to impart their site clickstream information to different organizations by downloading and introducing specific clickstream accumulation operators.

**AREA OF COMPUTER SCIENCE:**

- AWS CLOUD

**HARDWARE REQUIREMENTS:**

- Personal Computer

**SOFTWARE  REQUIREMENTS:**

- AWS Cloud Architecture
- Apache kafka
- Kibana
- AWS Quicksight
- AWS VPC
- Redshift
- Kinesis Firehose
- AWS Simple Notification Service
- Elastic MapReduce
- Cloudwatch
- Hadoop 2.8.5
- Hive 2.3.5
- Hue 4.4.0
- Zeppelin 0.8.1
- Tez 0.9.2
- Pig 0.17.0
- Spark 2.4.4
- Oozie 5.1.0





**OBJECTIVES**

The primary objective of clickstream data analysis is to comprehend client conduct and website admins understanding into what guests are doing on their website. The information can be utilized for different reasons like user needs, other than this we will make sure that we can accept real time website clickstream data and analyse it accordingly.

**METHODOLOGY**

 

**IMPLEMENTATION  DETAILS**

1. **1.)**We will set up an environment on AWS and we would be analysing the Default Data Set provided by AWS or Cloudera because we do not have any source from where we can fetch Website logs.
2. **2.)**We will then use cloud services for data abstraction, analysis and visualization.
3. **3.)**As this is a Website Clickstream Visualization process, we will check how to accept real time data streaming from tools provided by AWS.





**CONTRIBUTION  SUMMARY**





**PROGRESS**

Till now we have set up the Big Data cluster on AWS cloud. The steps which we had used are as:

Step 1: Make AWS account.

Step 2: Navigate to EC2 -\&gt; Key Pairs -\&gt; Create A Key Pair.

Step 3: Launch EMR from Services Tab in AWS.

Step 4: Navigate to Clusters Tab.

Step 5: Create cluster.

Step 6: Go to Advanced Configuration Tab.

Step 7: Select EMR release 5.27.0

1. )Select Hadoop services Needed for Analytics
2. )Hadoop 2.8.5
3. )Hive 2.3.5
4. )Hue 4.4.0
5. )Zeppelin 0.8.1
6. )Tez 0.9.2
7. )Spark 2.4.4
8. )Pig 0.17.0
9. )Oozie 5.1.0

Step 8: Select Instance Group Configuration: Uniform Instance Groups.

Step 9: Select Default Network Configuration.

Step 10: Select Root device EBS Volume 10GB.

Step 11: Select Master Note Instance as m5.xlarge.

Step 12: Select 2 core instance of size m5.xlarge.

Step 13: Purchasing Option as Spot instance with cost 0.192$ per hour.

Step 14: Download Putty and PuttyGen.

Step 15: Convert Public Key File to Private Key file from PuttyGen.

Step 16:

1. Start PuTTY.
2. In the Category list, click Session.
3. In the Host Name field, type  **SSH input Hostname**
4. In the Category list, expand Connection \&gt; SSH, and then click Auth.
5. For Private key file for authentication, click Browse and select the private key file used to launch the cluster.
6. In the Category list, expand Connection \&gt; SSH, and then click Tunnels.
7. In the Source port field, type 8157 (a randomly chosen, unused local port).
8. Select the Dynamic and Auto options.
9. Leave the Destination field empty and click Add
10. Click Open.
11. Click Yes to dismiss the security alert.

Step 17: Now We will get a Command line where we can use our Hadoop commands.

Step 18: Storage is S3 Bucket by default.

Step 19: To Enable web Connection for Services like Hue, Zeppelin Notebook can Connect through proxy.

Step 20: Now using the data set provided from cloudera we will do the visualization if the above setup works fine for the default data set and we will also check whether this setup works fine for large data sets.



**REMAINING WORK**

- Testing If the setup works fine for Data Visualization and Analytics.
- To see other options available other than Elastic MapReduce Environment.
- Data Analysis
- Visualization

**REFRENCES**

- [https://www.cloudera.com/](https://www.cloudera.com/)
- [https://bigishere.wordpress.com/](https://bigishere.wordpress.com/)
- [https://www.oreilly.com](https://www.oreilly.com/)# visualise-website-clikstream-data
